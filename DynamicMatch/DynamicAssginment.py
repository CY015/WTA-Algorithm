import numpy as np
import math
import random
import time
from typing import List, Tuple, Dict, Callable
from StaticMatch.AHL_NSGA_II import AHLNSGAII_Solver, Target, Ammunition
from SituationReceiver import SituationReceiver  # å¯¼å…¥æ€åŠ¿æ¥æ”¶æ¨¡å—


class DynamicTargetWeaponAssignment:
    """ä»…æ”¯æŒç›®æ ‡æ–°å¢çš„åŠ¨æ€å¼¹ç›®åŒ¹é…æ¨¡å‹ï¼ˆåœ¨çº¿å¢é‡æ€åŠ¿æ¨¡å¼ï¼‰"""
    def __init__(self, initial_situation: Dict, adaptability_matrix: np.ndarray,
                 damage_threshold: float = 0.8, max_decision_time: float = 5.0):
        """
        åˆå§‹åŒ–ï¼šåŠ è½½åˆå§‹æ€åŠ¿ï¼Œå¯åŠ¨æ€åŠ¿æ¥æ”¶
        Args:
            initial_situation: åˆå§‹æ€åŠ¿ï¼ˆå«åˆå§‹ç›®æ ‡ã€åˆå§‹å¼¹è¯ï¼‰
            adaptability_matrix: å¼¹è¯-ç›®æ ‡é€‚é…æ€§çŸ©é˜µï¼ˆshape: [å¼¹è¯æ•°, æœ€å¤§ç›®æ ‡ID]ï¼‰
            damage_threshold: ç›®æ ‡æ¯ä¼¤é˜ˆå€¼ï¼ˆé»˜è®¤0.8ï¼‰
            max_decision_time: MCTSå•æ¬¡å†³ç­–æœ€å¤§æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤5ï¼‰
        """
        # 1. æ€åŠ¿æ¥æ”¶æ¨¡å—åˆå§‹åŒ–
        self.situation_receiver = SituationReceiver()
        self.situation_receiver.start()

        # 2. åˆå§‹çŠ¶æ€åŠ è½½ï¼ˆä»åˆå§‹æ€åŠ¿ä¸­æå–ï¼‰
        self.initial_timestamp = initial_situation["timestamp"]
        self.current_timestamp = self.initial_timestamp
        
        # 2.1 ç›®æ ‡ç®¡ç†ï¼š{ç›®æ ‡ID: Targetå¯¹è±¡}ï¼ˆä»…æ–°å¢ï¼Œä¸åˆ é™¤ï¼‰
        self.targets: Dict[int, Target] = {}
        for target in initial_situation["target_changes"]["add"]:
            self.targets[target.id] = target
        
        # 2.2 ç›®æ ‡æ¯ä¼¤çŠ¶æ€ï¼š{ç›®æ ‡ID: æ¯ä¼¤åº¦}ï¼ˆåˆå§‹0.0ï¼‰
        self.target_damage: Dict[int, float] = {tid: 0.0 for tid in self.targets.keys()}
        
        # 2.3 å¼¹è¯ç®¡ç†ï¼š{å¼¹è¯ID: Ammunitionå¯¹è±¡}
        self.ammos: Dict[int, Ammunition] = {}
        for ammo in initial_situation["ammo_changes"]["initial"]:
            self.ammos[ammo.id] = ammo
        
        # 2.4 å¼¹è¯åº“å­˜ï¼š{å¼¹è¯ID: å‰©ä½™æ•°é‡}ï¼ˆåˆå§‹ä¸ºæ»¡åº“å­˜ï¼‰
        self.ammo_stock: Dict[int, int] = {aid: ammo.stock for aid, ammo in self.ammos.items()}

        # 3. æ ¸å¿ƒç®—æ³•å‚æ•°
        self.adaptability_matrix = adaptability_matrix  # é€‚é…æ€§çŸ©é˜µï¼ˆå¼¹è¯æ•°Ã—æœ€å¤§ç›®æ ‡IDï¼‰
        self.damage_threshold = damage_threshold
        self.max_decision_time = max_decision_time  # MCTSå†³ç­–æ—¶é—´é™åˆ¶
        
        # MDPå‚æ•°ï¼ˆåŒ¹é…åŠ¨æ€.docxå®šä¹‰ï¼‰
        self.discount_factor = 0.95  # æŠ˜æ‰£å› å­Î³
        self.lambda_ = 10.0          # æ¯ä¼¤å¥–åŠ±æƒé‡
        self.mu_ = 0.1               # æˆæœ¬æƒ©ç½šæƒé‡
        self.eta_ = 1.0              # æ—¶é—´æƒ©ç½šæƒé‡
        
        # MCTSå‚æ•°
        self.exploration_constant = 1.41  # æ¢ç´¢å¸¸æ•°ï¼ˆâˆš2ï¼‰
        
        # 4. å†³ç­–çŠ¶æ€ç®¡ç†
        self.current_action: Optional[np.ndarray] = None  # å½“å‰æ‰§è¡Œçš„å¼¹è¯åˆ†é…åŠ¨ä½œ
        self.last_decision_timestamp = self.initial_timestamp  # ä¸Šæ¬¡å†³ç­–æ—¶é—´æˆ³
        self.decision_history: List[Tuple[Dict, np.ndarray, float]] = []  # å†³ç­–å†å²è®°å½•

    # ------------------------------
    # å†…éƒ¨çŠ¶æ€ç®¡ç†ï¼ˆå¢é‡æ›´æ–°ï¼‰
    # ------------------------------
    def _update_state(self, new_situation: Dict) -> bool:
        """
        å¢é‡æ›´æ–°å†…éƒ¨çŠ¶æ€ï¼ˆä»…å¤„ç†ç›®æ ‡æ–°å¢ã€æ¯ä¼¤ä¿®æ­£ã€å¼¹è¯è¡¥å……ï¼‰
        Returns: æ˜¯å¦éœ€è¦è§¦å‘é‡æ–°å†³ç­–
        """
        # 1. æ›´æ–°æ—¶é—´æˆ³
        self.current_timestamp = new_situation["timestamp"]
        need_redecision = new_situation["need_redecision"]

        # 2. å¤„ç†ç›®æ ‡æ–°å¢
        for new_target in new_situation["target_changes"]["add"]:
            if new_target.id not in self.targets:
                self.targets[new_target.id] = new_target
                self.target_damage[new_target.id] = 0.0  # æ–°å¢ç›®æ ‡åˆå§‹æ¯ä¼¤åº¦0.0
                print(f"ğŸ¯ æ–°å¢ç›®æ ‡ï¼šID={new_target.id}ï¼Œä»·å€¼={new_target.value:.0f}ï¼Œéƒ¨ä»¶æ•°={len(new_target.components)}")

        # 3. å¤„ç†ç›®æ ‡æ¯ä¼¤åº¦ä¿®æ­£ï¼ˆå¦‚æ¢æµ‹åå·®ï¼‰
        for update in new_situation["target_changes"]["update"]:
            tid = update["target_id"]
            new_damage = update["new_damage"]
            if tid in self.target_damage:
                old_damage = self.target_damage[tid]
                self.target_damage[tid] = new_damage
                print(f"ğŸ”„ ä¿®æ­£ç›®æ ‡{tid}æ¯ä¼¤åº¦ï¼š{old_damage:.2f} â†’ {new_damage:.2f}")

        # 4. å¤„ç†å¼¹è¯è¡¥å……
        for ammo_add in new_situation["ammo_changes"]["add"]:
            aid = ammo_add["ammo_id"]
            add_stock = ammo_add["add_stock"]
            if aid in self.ammo_stock:
                self.ammo_stock[aid] += add_stock
                print(f"ğŸ’¥ è¡¥å……å¼¹è¯{aid}ï¼š+{add_stock}å‘ â†’ æ€»åº“å­˜={self.ammo_stock[aid]}å‘")

        return need_redecision

    def _get_current_state_snapshot(self) -> Dict:
        """è·å–å½“å‰çŠ¶æ€å¿«ç…§ï¼ˆç”¨äºå†³ç­–å†å²è®°å½•ï¼‰"""
        return {
            "timestamp": self.current_timestamp,
            "targets": {tid: t.value for tid, t in self.targets.items()},
            "target_damage": self.target_damage.copy(),
            "ammo_stock": self.ammo_stock.copy(),
            "active_targets": [tid for tid, d in self.target_damage.items() if d < self.damage_threshold]  # æœªè¾¾æ¯ä¼¤é˜ˆå€¼çš„ç›®æ ‡
        }

    # ------------------------------
    # MCTSæ ¸å¿ƒé€»è¾‘ï¼ˆé€‚é…ç›®æ ‡æ–°å¢ï¼‰
    # ------------------------------
    class State:
        """MCTSçŠ¶æ€ç±»ï¼ˆé€‚é…åŠ¨æ€ç›®æ ‡æ•°é‡ï¼‰"""
        def __init__(self, target_damage: List[float], ammo_stocks: List[float], time_step: int):
            self.target_damage = target_damage  # å½“å‰æ´»è·ƒç›®æ ‡çš„æ¯ä¼¤åº¦åˆ—è¡¨ï¼ˆæŒ‰IDæ’åºï¼‰
            self.ammo_stocks = ammo_stocks      # å¼¹è¯åº“å­˜åˆ—è¡¨ï¼ˆæŒ‰IDæ’åºï¼‰
            self.time_step = time_step          # æ—¶é—´æ­¥ï¼ˆå½“å‰æ—¶é—´æˆ³-åˆå§‹æ—¶é—´æˆ³ï¼‰

        def __hash__(self):
            return hash((tuple(self.target_damage), tuple(self.ammo_stocks), self.time_step))

        def __eq__(self, other):
            return (tuple(self.target_damage) == tuple(other.target_damage) and
                    tuple(self.ammo_stocks) == tuple(other.ammo_stocks) and
                    self.time_step == other.time_step)

        def is_terminal(self, max_active_targets: int) -> bool:
            """ç»ˆæ­¢æ¡ä»¶ï¼šæ‰€æœ‰æ´»è·ƒç›®æ ‡å·²è¾¾æ¯ä¼¤é˜ˆå€¼"""
            return len([d for d in self.target_damage if d < 0.8]) == 0 or max_active_targets == 0

    class MCTSNode:
        """MCTSèŠ‚ç‚¹ç±»ï¼ˆUCTç®—æ³•ï¼‰"""
        def __init__(self, state: 'DynamicTargetWeaponAssignment.State', parent=None, action=None):
            self.state = state
            self.parent = parent
            self.action = action
            self.children = []
            self.visit_count = 0
            self.total_reward = 0.0
            self.untried_actions = None

        def is_fully_expanded(self) -> bool:
            return len(self.untried_actions) == 0

        def best_child(self, exploration_constant: float) -> 'DynamicTargetWeaponAssignment.MCTSNode':
            """UCTé€‰æ‹©ï¼šå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨"""
            best_score = -float('inf')
            best_child = None
            for child in self.children:
                if child.visit_count == 0:
                    score = float('inf')
                else:
                    exploitation = child.total_reward / child.visit_count
                    exploration = exploration_constant * math.sqrt(math.log(self.visit_count) / child.visit_count)
                    score = exploitation + exploration
                if score > best_score:
                    best_score = score
                    best_child = child
            return best_child

        def expand(self, action: np.ndarray, next_state: 'DynamicTargetWeaponAssignment.State') -> 'DynamicTargetWeaponAssignment.MCTSNode':
            """æ‰©å±•èŠ‚ç‚¹ï¼šæ·»åŠ æ–°å­èŠ‚ç‚¹"""
            child = self.__class__(next_state, self, action)
            self.children.append(child)
            if action in self.untried_actions:
                self.untried_actions.remove(action)
            return child

    def _create_mcts_initial_state(self) -> State:
        """åˆ›å»ºMCTSåˆå§‹çŠ¶æ€ï¼ˆæŒ‰IDæ’åºï¼Œä»…åŒ…å«æœªè¾¾æ¯ä¼¤é˜ˆå€¼çš„ç›®æ ‡ï¼‰"""
        # ç­›é€‰æ´»è·ƒç›®æ ‡ï¼ˆæœªè¾¾æ¯ä¼¤é˜ˆå€¼ï¼‰
        active_tids = sorted([tid for tid, d in self.target_damage.items() if d < self.damage_threshold])
        # ç›®æ ‡æ¯ä¼¤åº¦åˆ—è¡¨ï¼ˆæŒ‰IDæ’åºï¼‰
        target_damage = [self.target_damage[tid] for tid in active_tids]
        # å¼¹è¯åº“å­˜åˆ—è¡¨ï¼ˆæŒ‰IDæ’åºï¼‰
        ammo_stocks = [self.ammo_stock[aid] for aid in sorted(self.ammos.keys())]
        # æ—¶é—´æ­¥ï¼ˆå½“å‰æ—¶é—´æˆ³-åˆå§‹æ—¶é—´æˆ³ï¼Œå–æ•´ï¼‰
        time_step = int(self.current_timestamp - self.initial_timestamp)
        return self.State(target_damage, ammo_stocks, time_step)

    def _get_active_targets(self) -> List[Target]:
        """è·å–å½“å‰æ´»è·ƒç›®æ ‡ï¼ˆæœªè¾¾æ¯ä¼¤é˜ˆå€¼ï¼‰"""
        return [self.targets[tid] for tid in sorted(self.targets.keys()) if self.target_damage[tid] < self.damage_threshold]

    def _get_ammo_list(self) -> List[Ammunition]:
        """è·å–å¼¹è¯åˆ—è¡¨ï¼ˆæŒ‰IDæ’åºï¼‰"""
        return [self.ammos[aid] for aid in sorted(self.ammos.keys())]

    def _calculate_damage_efficiency(self, ammo_idx: int, target_idx: int, active_tids: List[int]) -> float:
        """è®¡ç®—å•å‘å¼¹è¯æ¯ä¼¤æ•ˆèƒ½ï¼ˆé€‚é…æ´»è·ƒç›®æ ‡ç´¢å¼•ï¼‰"""
        ammo = self._get_ammo_list()[ammo_idx]
        target_id = active_tids[target_idx]
        target = self.targets[target_id]
        
        # å¼¹è¯å¯¹ç›®æ ‡çš„æ¯ä¼¤æ¦‚ç‡å‰–é¢ï¼ˆæ— åˆ™é»˜è®¤0.1ï¼‰
        damage_prob = ammo.damage_profiles.get(target_id, [0.1] * len(target.components))
        # é€‚é…æ€§ç³»æ•°ï¼ˆä»çŸ©é˜µä¸­æå–ï¼Œç›®æ ‡IDä»1å¼€å§‹ï¼ŒçŸ©é˜µåˆ—ç´¢å¼•ä»0å¼€å§‹ï¼‰
        adaptability = self.adaptability_matrix[ammo_idx, target_id - 1] if target_id - 1 < self.adaptability_matrix.shape[1] else 0.5
        
        # åŠ æƒæ¯ä¼¤æ•ˆèƒ½è®¡ç®—ï¼ˆå¤ç”¨AHL-NSGA-IIé€»è¾‘ï¼‰
        weighted_damage = 0.0
        for (weight, health), prob in zip(target.components, damage_prob):
            weighted_damage += weight * prob * health
        return adaptability * weighted_damage

    def _generate_candidate_actions(self, active_targets: List[Target], ammo_list: List[Ammunition]) -> List[np.ndarray]:
        """è°ƒç”¨AHL-NSGA-IIç”Ÿæˆå€™é€‰åŠ¨ä½œï¼ˆä»…é’ˆå¯¹æ´»è·ƒç›®æ ‡ï¼‰"""
        if not active_targets:
            return [np.zeros((len(ammo_list), 0), dtype=int)]
        
        # æ„é€ ä¸´æ—¶å¼¹è¯ï¼ˆä¼ é€’å½“å‰åº“å­˜ï¼‰
        class TempAmmo:
            def __init__(self, ammo: Ammunition, stock: int):
                self.id = ammo.id
                self.cost = ammo.cost
                self.stock = stock
                self.damage_profiles = ammo.damage_profiles
        
        temp_ammos = [TempAmmo(ammo, self.ammo_stock[ammo.id]) for ammo in ammo_list]
        
        # æ„é€ å½“å‰æ´»è·ƒç›®æ ‡çš„é€‚é…æ€§çŸ©é˜µï¼ˆä»…æå–æ´»è·ƒç›®æ ‡å¯¹åº”çš„åˆ—ï¼‰
        active_tids = [t.id for t in active_targets]
        current_adapt_matrix = self.adaptability_matrix[:, [tid - 1 for tid in active_tids]]
        
        # è°ƒç”¨AHL-NSGA-IIç”Ÿæˆå¸•ç´¯æ‰˜æœ€ä¼˜åŠ¨ä½œ
        try:
            static_solver = AHLNSGAII_Solver(
                targets=active_targets,
                ammunitions=temp_ammos,
                adaptability_matrix=current_adapt_matrix,
                damage_threshold=self.damage_threshold
            )
            pareto_solutions, _ = static_solver.solve()
            return [sol[0] for sol in pareto_solutions]  # æå–åˆ†é…çŸ©é˜µä½œä¸ºå€™é€‰åŠ¨ä½œ
        except Exception as e:
            print(f"AHL-NSGA-IIè°ƒç”¨å¤±è´¥ï¼Œç”ŸæˆéšæœºåŠ¨ä½œï¼š{str(e)}")
            return self._generate_random_actions(active_targets, ammo_list)

    def _generate_random_actions(self, active_targets: List[Target], ammo_list: List[Ammunition], num: int = 3) -> List[np.ndarray]:
        """ç”ŸæˆéšæœºåŠ¨ä½œï¼ˆAHL-NSGA-IIå¤±æ•ˆæ—¶å¤‡ç”¨ï¼‰"""
        actions = []
        ammo_count = len(ammo_list)
        target_count = len(active_targets)
        
        for _ in range(num):
            action = np.zeros((ammo_count, target_count), dtype=int)
            for j in range(target_count):
                # ä»…å¯¹æ´»è·ƒç›®æ ‡åˆ†é…1-2å‘æœ‰åº“å­˜çš„å¼¹è¯
                available_ammos = [i for i in range(ammo_count) if self.ammo_stock[ammo_list[i].id] > 0]
                if available_ammos:
                    ammo_idx = random.choice(available_ammos)
                    max_rounds = min(2, self.ammo_stock[ammo_list[ammo_idx].id])
                    action[ammo_idx, j] = random.randint(1, max_rounds)
            actions.append(action)
        return actions

    def mcts_search(self, initial_state: State) -> np.ndarray:
        """MCTSæ ¸å¿ƒæœç´¢ï¼ˆæŒ‰æ—¶é—´é™åˆ¶ç»ˆæ­¢ï¼‰"""
        start_time = time.time()
        root = self.MCTSNode(initial_state)
        active_targets = self._get_active_targets()
        ammo_list = self._get_ammo_list()
        root.untried_actions = self._generate_candidate_actions(active_targets, ammo_list)

        # æœç´¢å¾ªç¯ï¼ˆæŒ‰æ—¶é—´é™åˆ¶ç»ˆæ­¢ï¼‰
        while time.time() - start_time < self.max_decision_time:
            # 1. é€‰æ‹©é˜¶æ®µï¼šä»æ ¹èŠ‚ç‚¹å‘ä¸‹é€‰æ‹©
            current_node = self._mcts_select(root)
            
            # 2. æ‰©å±•é˜¶æ®µï¼šè‹¥æœªç»ˆæ­¢ä¸”æœªå®Œå…¨æ‰©å±•ï¼Œç”Ÿæˆæ–°å­èŠ‚ç‚¹
            if not current_node.state.is_terminal(len(active_targets)) and not current_node.is_fully_expanded():
                action = random.choice(current_node.untried_actions)
                next_state = self._mcts_transition(current_node.state, action)
                current_node = current_node.expand(action, next_state)
            
            # 3. æ¨¡æ‹Ÿé˜¶æ®µï¼šéšæœºrolloutåˆ°ç»ˆæ­¢çŠ¶æ€
            reward = self._mcts_simulate(current_node, active_targets, ammo_list)
            
            # 4. å›æº¯é˜¶æ®µï¼šæ›´æ–°èŠ‚ç‚¹å¥–åŠ±
            self._mcts_backpropagate(current_node, reward)

        # é€‰æ‹©è®¿é—®æ¬¡æ•°æœ€å¤šçš„åŠ¨ä½œï¼ˆæœ€å¯é ï¼‰
        return max(root.children, key=lambda c: c.visit_count).action if root.children else np.zeros((len(ammo_list), len(active_targets)), dtype=int)

    def _mcts_select(self, root: MCTSNode) -> MCTSNode:
        """MCTSé€‰æ‹©é˜¶æ®µï¼šé€’å½’é€‰æ‹©æœ€ä¼˜å­èŠ‚ç‚¹"""
        current_node = root
        active_target_count = len(self._get_active_targets())
        while not current_node.state.is_terminal(active_target_count) and current_node.is_fully_expanded():
            current_node = current_node.best_child(self.exploration_constant)
        return current_node

    def _mcts_transition(self, state: State, action: np.ndarray) -> State:
        """MCTSçŠ¶æ€è½¬ç§»ï¼ˆæ¨¡æ‹ŸåŠ¨ä½œæ‰§è¡Œåçš„çŠ¶æ€ï¼‰"""
        new_state = self.State(state.target_damage.copy(), state.ammo_stocks.copy(), state.time_step + 1)
        active_tids = sorted([tid for tid, d in self.target_damage.items() if d < self.damage_threshold])
        
        # 1. æ›´æ–°å¼¹è¯åº“å­˜
        for i in range(len(new_state.ammo_stocks)):
            new_state.ammo_stocks[i] = max(0, new_state.ammo_stocks[i] - np.sum(action[i, :]))
        
        # 2. æ›´æ–°ç›®æ ‡æ¯ä¼¤åº¦
        for j in range(len(new_state.target_damage)):
            if new_state.target_damage[j] >= self.damage_threshold:
                continue
            # è®¡ç®—ç»¼åˆæ¯ä¼¤æ¦‚ç‡
            survival_prob = 1.0
            for i in range(len(action)):
                rounds = action[i, j]
                if rounds <= 0:
                    continue
                e_ij = self._calculate_damage_efficiency(i, j, active_tids)
                survival_prob *= (1 - e_ij) ** rounds
            damage_prob = 1 - survival_prob
            
            # æŠ½æ ·æ›´æ–°æ¯ä¼¤åº¦
            if random.random() < damage_prob:
                damage_increment = random.betavariate(2, 5)  # Betaåˆ†å¸ƒæ¨¡æ‹Ÿæ¯ä¼¤å¢é‡
                new_state.target_damage[j] = min(1.0, new_state.target_damage[j] + damage_increment)
        
        return new_state

    def _mcts_simulate(self, node: MCTSNode, active_targets: List[Target], ammo_list: List[Ammunition]) -> float:
        """MCTSæ¨¡æ‹Ÿé˜¶æ®µï¼ˆå¯å‘å¼ç­–ç•¥ï¼šä¼˜å…ˆé«˜è´¹æ•ˆæ¯”å¼¹è¯ï¼‰"""
        current_state = self.State(node.state.target_damage.copy(), node.state.ammo_stocks.copy(), node.state.time_step)
        total_reward = 0.0
        discount = 1.0
        active_tids = sorted([tid for tid, d in self.target_damage.items() if d < self.damage_threshold])

        while not current_state.is_terminal(len(active_targets)):
            # å¯å‘å¼åŠ¨ä½œç”Ÿæˆï¼šé€‰æ‹©è´¹æ•ˆæ¯”æœ€é«˜çš„å¼¹è¯
            action = np.zeros((len(ammo_list), len(current_state.target_damage)), dtype=int)
            for j in range(len(current_state.target_damage)):
                if current_state.target_damage[j] >= self.damage_threshold:
                    continue
                # è®¡ç®—å„å¼¹è¯è´¹æ•ˆæ¯”ï¼ˆæ¯ä¼¤æ•ˆèƒ½/æˆæœ¬ï¼‰
                ammo_efficiency = []
                for i in range(len(ammo_list)):
                    if current_state.ammo_stocks[i] <= 0:
                        continue
                    e_ij = self._calculate_damage_efficiency(i, j, active_tids)
                    cost = ammo_list[i].cost
                    efficiency = e_ij / cost if cost > 1e-6 else 0.0
                    ammo_efficiency.append((i, efficiency))
                # é€‰æ‹©è´¹æ•ˆæ¯”æœ€é«˜çš„å¼¹è¯åˆ†é…
                if ammo_efficiency:
                    best_ammo_idx = max(ammo_efficiency, key=lambda x: x[1])[0]
                    max_rounds = min(2, current_state.ammo_stocks[best_ammo_idx])
                    action[best_ammo_idx, j] = max_rounds
            
            # çŠ¶æ€è½¬ç§»
            next_state = self._mcts_transition(current_state, action)
            
            # è®¡ç®—å¥–åŠ±
            reward = self._calculate_reward(current_state, next_state, action, active_targets, ammo_list)
            total_reward += discount * reward
            
            # æ›´æ–°çŠ¶æ€å’ŒæŠ˜æ‰£å› å­
            current_state = next_state
            discount *= self.discount_factor

        return total_reward

    def _calculate_reward(self, state: State, next_state: State, action: np.ndarray,
                         active_targets: List[Target], ammo_list: List[Ammunition]) -> float:
        """è®¡ç®—MCTSå¥–åŠ±ï¼ˆåŒ¹é…åŠ¨æ€.docxå…¬å¼ï¼‰"""
        # 1. æ¯ä¼¤å¥–åŠ±ï¼ˆæ–°å¢ç›®æ ‡æ¯ä¼¤ä»·å€¼ï¼‰
        damage_reward = 0.0
        for j in range(len(state.target_damage)):
            damage_increase = next_state.target_damage[j] - state.target_damage[j]
            damage_reward += active_targets[j].value * damage_increase
        
        # 2. æˆæœ¬æƒ©ç½šï¼ˆå¼¹è¯æ¶ˆè€—æˆæœ¬ï¼‰
        cost_penalty = 0.0
        for i in range(len(action)):
            rounds_used = np.sum(action[i, :])
            cost_penalty += ammo_list[i].cost * rounds_used
        
        # 3. æ—¶é—´æƒ©ç½šï¼ˆæ€»å¼¹è¯æ¶ˆè€—é‡Ã—å•ä½æ—¶é—´ï¼‰
        time_penalty = np.sum(action) * 0.5  # å¤ç”¨AHL-NSGA-IIæ—¶é—´è®¡ç®—é€»è¾‘
        
        # 4. ç»¼åˆå¥–åŠ±ï¼ˆåŠ æƒå’Œï¼‰
        return self.lambda_ * damage_reward - self.mu_ * cost_penalty - self.eta_ * time_penalty

    def _mcts_backpropagate(self, node: MCTSNode, reward: float):
        """MCTSå›æº¯é˜¶æ®µï¼šæ›´æ–°èŠ‚ç‚¹è®¿é—®æ¬¡æ•°å’Œå¥–åŠ±"""
        current_node = node
        while current_node is not None:
            current_node.visit_count += 1
            current_node.total_reward += reward
            current_node = current_node.parent

    # ------------------------------
    # åœ¨çº¿å†³ç­–å¾ªç¯
    # ------------------------------
    def _print_current_decision(self, action: np.ndarray, active_targets: List[Target], ammo_list: List[Ammunition]):
        """æ‰“å°å½“å‰å†³ç­–ç»“æœï¼ˆå¼¹è¯åˆ†é…è¯¦æƒ…ï¼‰"""
        print("\n" + "=" * 60)
        print(f"å½“å‰å†³ç­–ï¼ˆæ—¶é—´æˆ³ï¼š{self.current_timestamp:.0f}ï¼‰")
        print(f"æ´»è·ƒç›®æ ‡æ•°ï¼š{len(active_targets)}ï¼Œå‰©ä½™å¼¹è¯æ€»é‡ï¼š{sum(self.ammo_stock.values())}")
        print("=" * 60)
        
        for j, target in enumerate(active_targets):
            target_id = target.id
            ammo_details = []
            total_rounds = 0
            for i, ammo in enumerate(ammo_list):
                rounds = action[i, j]
                if rounds > 0:
                    ammo_details.append(f"å¼¹è¯{ammo.id}ï¼ˆæˆæœ¬{ammo.cost}ï¼‰ï¼š{rounds}å‘")
                    total_rounds += rounds
            if ammo_details:
                print(f"ğŸ¯ ç›®æ ‡{target_id}ï¼ˆä»·å€¼{target.value:.0f}ï¼Œå½“å‰æ¯ä¼¤{self.target_damage[target_id]:.2f}ï¼‰ï¼š")
                print(f"   åˆ†é…ï¼šå…±{total_rounds}å‘ â†’ {', '.join(ammo_details)}")
                # é¢„æµ‹æ¯ä¼¤åº¦ï¼ˆåŸºäºå½“å‰åˆ†é…ï¼‰
                e_ij_list = [self._calculate_damage_efficiency(i, j, [t.id for t in active_targets]) for i in range(len(ammo_list))]
                survival_prob = 1.0
                for i, rounds in enumerate(action[:, j]):
                    if rounds > 0:
                        survival_prob *= (1 - e_ij_list[i]) ** rounds
                predicted_damage = min(1.0, self.target_damage[target_id] + (1 - survival_prob))
                print(f"   é¢„æµ‹æ¯ä¼¤åº¦ï¼š{predicted_damage:.2f}ï¼ˆ{'è¾¾æ ‡' if predicted_damage >= self.damage_threshold else 'æœªè¾¾æ ‡'}ï¼‰")
            else:
                print(f"ğŸ¯ ç›®æ ‡{target_id}ï¼ˆä»·å€¼{target.value:.0f}ï¼Œå½“å‰æ¯ä¼¤{self.target_damage[target_id]:.2f}ï¼‰ï¼šæ— å¼¹è¯åˆ†é…")
        print("=" * 60 + "\n")

    def _simulate_action_execution(self, step_duration: float = 1.0):
        """æ¨¡æ‹ŸåŠ¨ä½œæ‰§è¡Œï¼šæ¯é—´éš”1ç§’æ›´æ–°ä¸€æ¬¡ç›®æ ‡æ¯ä¼¤åº¦ï¼ˆåæ˜ æ—¶é—´æµé€ï¼‰"""
        if self.current_action is None:
            return
        
        active_targets = self._get_active_targets()
        if not active_targets:
            return
        
        ammo_list = self._get_ammo_list()
        active_tids = [t.id for t in active_targets]
        
        # æŒ‰åŠ¨ä½œåˆ†é…æ›´æ–°æ¯ä¼¤åº¦ï¼ˆç®€åŒ–ä¸ºæ¯1ç§’æ›´æ–°ä¸€æ¬¡ï¼‰
        for j, target_id in enumerate(active_tids):
            if self.target_damage[target_id] >= self.damage_threshold:
                continue
            
            # è®¡ç®—ç»¼åˆæ¯ä¼¤æ¦‚ç‡
            survival_prob = 1.0
            for i in range(len(ammo_list)):
                rounds = self.current_action[i, j] if j < self.current_action.shape[1] else 0
                if rounds <= 0:
                    continue
                e_ij = self._calculate_damage_efficiency(i, j, active_tids)
                survival_prob *= (1 - e_ij) ** rounds
            damage_prob = 1 - survival_prob
        
            # æŒ‰æ—¶é—´æ­¥æ¯”ä¾‹æ›´æ–°æ¯ä¼¤åº¦ï¼ˆ1ç§’å æ€»æ‰“å‡»æ—¶é—´çš„æ¯”ä¾‹ï¼‰
            if random.random() < damage_prob * (step_duration / 10.0):  # å‡è®¾10ç§’å®Œæˆä¸€æ¬¡å®Œæ•´æ‰“å‡»
                damage_increment = random.betavariate(2, 5) * (step_duration / 10.0)
                self.target_damage[target_id] = min(1.0, self.target_damage[target_id] + damage_increment)
        
        # æ›´æ–°å½“å‰æ—¶é—´æˆ³ï¼ˆæ¨¡æ‹Ÿæ—¶é—´æµé€ï¼‰
        self.current_timestamp += step_duration

    def run_online_loop(self, task_end_condition: Callable[['DynamicTargetWeaponAssignment'], bool]):
        """
        åœ¨çº¿å†³ç­–å¾ªç¯ï¼šä¸å®šæ—¶æ¥æ”¶æ€åŠ¿ï¼Œè§¦å‘å†³ç­–æˆ–æ¨¡æ‹ŸåŠ¨ä½œæ‰§è¡Œ
        Args:
            task_end_condition: ä»»åŠ¡ç»“æŸæ¡ä»¶ï¼ˆå¦‚â€œæ‰€æœ‰ç›®æ ‡æ‘§æ¯â€æˆ–â€œæ‰‹åŠ¨åœæ­¢â€ï¼‰
        """
        print("\n" + "=" * 80)
        print("åŠ¨æ€å¼¹ç›®åŒ¹é…åœ¨çº¿å†³ç­–å¾ªç¯å¯åŠ¨ï¼ˆä»…æ”¯æŒç›®æ ‡æ–°å¢ï¼‰")
        print(f"åˆå§‹çŠ¶æ€ï¼šç›®æ ‡{list(self.targets.keys())}ï¼Œå¼¹è¯{list(self.ammos.keys())}ï¼Œæ—¶é—´æˆ³={self.initial_timestamp:.0f}")
        print("=" * 80 + "\n")

        # é¦–æ¬¡å†³ç­–ï¼ˆåŸºäºåˆå§‹æ€åŠ¿ï¼‰
        active_targets = self._get_active_targets()
        if active_targets:
            print("ğŸ” åŸºäºåˆå§‹æ€åŠ¿å¯åŠ¨é¦–æ¬¡å†³ç­–...")
            initial_mcts_state = self._create_mcts_initial_state()
            self.current_action = self.mcts_search(initial_mcts_state)
            self.decision_history.append((
                self._get_current_state_snapshot(),
                self.current_action.copy(),
                self.current_timestamp
            ))
            self._print_current_decision(self.current_action, active_targets, self._get_ammo_list())
            self.last_decision_timestamp = self.current_timestamp

        try:
            while not task_end_condition(self):
                # 1. æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ€åŠ¿ï¼ˆè¶…æ—¶1ç§’é¿å…é˜»å¡ï¼‰
                if self.situation_receiver.wait_for_situation(timeout=1.0):
                    new_situation = self.situation_receiver.get_new_situation()
                    if new_situation:
                        # 1.1 å¢é‡æ›´æ–°çŠ¶æ€
                        need_redecision = self._update_state(new_situation)
                        # 1.2 è‹¥éœ€è¦ï¼Œè§¦å‘é‡æ–°å†³ç­–
                        if need_redecision:
                            active_targets = self._get_active_targets()
                            if active_targets:
                                print("ğŸ” æ€åŠ¿æ›´æ–°ï¼Œå¯åŠ¨é‡æ–°å†³ç­–...")
                                mcts_state = self._create_mcts_initial_state()
                                self.current_action = self.mcts_search(mcts_state)
                                # è®°å½•å†³ç­–å†å²
                                self.decision_history.append((
                                    self._get_current_state_snapshot(),
                                    self.current_action.copy(),
                                    self.current_timestamp
                                ))
                                # æ‰“å°å†³ç­–ç»“æœ
                                self._print_current_decision(self.current_action, active_targets, self._get_ammo_list())
                                self.last_decision_timestamp = self.current_timestamp
                            else:
                                print("â„¹ï¸  æ— æ´»è·ƒç›®æ ‡ï¼Œæ— éœ€å†³ç­–")
                else:
                    # 2. æ— æ–°æ€åŠ¿ï¼šæ¨¡æ‹ŸåŠ¨ä½œæ‰§è¡Œï¼ˆæ¯1ç§’æ›´æ–°ä¸€æ¬¡æ¯ä¼¤åº¦ï¼‰
                    self._simulate_action_execution(step_duration=1.0)
                    # 2.1 å®šæœŸæ£€æŸ¥åŠ¨ä½œæ˜¯å¦è¿‡æœŸï¼ˆå¦‚30ç§’æœªæ›´æ–°åˆ™é‡æ–°å†³ç­–ï¼Œé¿å…åŠ¨ä½œå¤±æ•ˆï¼‰
                    action_valid_duration = 30.0
                    if self.current_timestamp - self.last_decision_timestamp > action_valid_duration:
                        active_targets = self._get_active_targets()
                        if active_targets:
                            print(f"ğŸ” åŠ¨ä½œå·²è¿‡æœŸï¼ˆ{action_valid_duration}ç§’ï¼‰ï¼Œå¯åŠ¨é‡æ–°å†³ç­–...")
                            mcts_state = self._create_mcts_initial_state()
                            self.current_action = self.mcts_search(mcts_state)
                            self.decision_history.append((
                                self._get_current_state_snapshot(),
                                self.current_action.copy(),
                                self.current_timestamp
                            ))
                            self._print_current_decision(self.current_action, active_targets, self._get_ammo_list())
                            self.last_decision_timestamp = self.current_timestamp

        except KeyboardInterrupt:
            print("\nâš ï¸  æ‰‹åŠ¨åœæ­¢åœ¨çº¿å†³ç­–å¾ªç¯")
        finally:
            # åœæ­¢æ€åŠ¿æ¥æ”¶ï¼Œè¾“å‡ºå†³ç­–å†å²
            self.situation_receiver.stop()
            self._print_decision_history()

    def _print_decision_history(self):
        """æ‰“å°å†³ç­–å†å²æ±‡æ€»"""
        print("\n" + "=" * 80)
        print(f"å†³ç­–å†å²æ±‡æ€»ï¼ˆå…±{len(self.decision_history)}æ¬¡å†³ç­–ï¼‰")
        print("=" * 80)
        for i, (state, action, timestamp) in enumerate(self.decision_history, 1):
            print(f"\nå†³ç­–{i}ï¼ˆæ—¶é—´æˆ³ï¼š{timestamp:.0f}ï¼‰ï¼š")
            print(f"  æ´»è·ƒç›®æ ‡ï¼š{state['active_targets']}")
            print(f"  ç›®æ ‡æ¯ä¼¤ï¼š{ {tid: f'{d:.2f}' for tid, d in state['target_damage'].items()} }")
            print(f"  å¼¹è¯åº“å­˜ï¼š{state['ammo_stock']}")
            print(f"  åŠ¨ä½œç»´åº¦ï¼š{action.shape}ï¼ˆå¼¹è¯æ•°Ã—ç›®æ ‡æ•°ï¼‰")
        print("\n" + "=" * 80)


# ------------------------------
# ä»»åŠ¡ç»“æŸæ¡ä»¶ä¸æµ‹è¯•å…¥å£
# ------------------------------
def task_end_condition(solver: DynamicTargetWeaponAssignment) -> bool:
    """ä»»åŠ¡ç»“æŸæ¡ä»¶ï¼šæ‰€æœ‰ç›®æ ‡å·²è¾¾æ¯ä¼¤é˜ˆå€¼ æˆ– æ‰‹åŠ¨åœæ­¢ï¼ˆCtrl+Cï¼‰"""
    all_destroyed = all(d >= solver.damage_threshold for d in solver.target_damage.values())
    if all_destroyed:
        print("\nğŸ‰ æ‰€æœ‰ç›®æ ‡å·²è¾¾æ¯ä¼¤é˜ˆå€¼ï¼Œä»»åŠ¡ç»“æŸï¼")
        return True
    return False


def main():
    # 1. å‡†å¤‡åˆå§‹æ€åŠ¿ï¼ˆç¬¬ä¸€æ¬¡è¾“å…¥ï¼Œå«åˆå§‹ç›®æ ‡å’Œå¼¹è¯ï¼‰
    initial_timestamp = time.time()
    initial_situation = {
        "timestamp": initial_timestamp,
        "target_changes": {
            "add": [
                Target(id=1, value=100.0, components=[(0.3, 1.0), (0.4, 1.0), (0.3, 1.0)]),  # ç›®æ ‡1ï¼š3éƒ¨ä»¶ï¼Œä»·å€¼100
                Target(id=2, value=80.0, components=[(0.5, 1.0), (0.5, 1.0)])               # ç›®æ ‡2ï¼š2éƒ¨ä»¶ï¼Œä»·å€¼80
            ]
        },
        "ammo_changes": {
            "initial": [
                Ammunition(id=1, cost=10.0, stock=30, damage_profiles={  # å¼¹è¯1ï¼šæˆæœ¬10ï¼Œåº“å­˜30
                    1: [0.6, 0.4, 0.5],  # å¯¹ç›®æ ‡1çš„éƒ¨ä»¶æ¯ä¼¤æ¦‚ç‡
                    2: [0.7, 0.5],       # å¯¹ç›®æ ‡2çš„éƒ¨ä»¶æ¯ä¼¤æ¦‚ç‡
                    3: [0.5, 0.6, 0.4, 0.3],  # é¢„ç•™ç›®æ ‡3çš„æ¯ä¼¤æ¦‚ç‡
                    4: [0.6, 0.4, 0.5],  # é¢„ç•™ç›®æ ‡4çš„æ¯ä¼¤æ¦‚ç‡
                    5: [0.7, 0.5]        # é¢„ç•™ç›®æ ‡5çš„æ¯ä¼¤æ¦‚ç‡
                }),
                Ammunition(id=2, cost=15.0, stock=30, damage_profiles={  # å¼¹è¯2ï¼šæˆæœ¬15ï¼Œåº“å­˜30
                    1: [0.8, 0.6, 0.7],
                    2: [0.6, 0.7],
                    3: [0.7, 0.5, 0.6, 0.5],
                    4: [0.8, 0.6, 0.7],
                    5: [0.6, 0.7]
                }),
                Ammunition(id=3, cost=25.0, stock=30, damage_profiles={  # å¼¹è¯3ï¼šæˆæœ¬25ï¼Œåº“å­˜30ï¼ˆé«˜å¨åŠ›ï¼‰
                    1: [0.9, 0.8, 0.85],
                    2: [0.85, 0.9],
                    3: [0.8, 0.7, 0.75, 0.8],
                    4: [0.9, 0.8, 0.85],
                    5: [0.85, 0.9]
                })
            ]
        }
    }

    # 2. é€‚é…æ€§çŸ©é˜µï¼ˆshape: [å¼¹è¯æ•°, æœ€å¤§ç›®æ ‡ID]ï¼Œé¢„ç•™5ä¸ªç›®æ ‡çš„é€‚é…æ€§ï¼‰
    adaptability_matrix = np.array([
        [0.8, 0.7, 0.6, 0.8, 0.7],  # å¼¹è¯1ï¼šç›®æ ‡1-5çš„é€‚é…æ€§
        [0.9, 0.8, 0.7, 0.9, 0.8],  # å¼¹è¯2ï¼šç›®æ ‡1-5çš„é€‚é…æ€§
        [0.7, 0.9, 0.8, 0.7, 0.9]   # å¼¹è¯3ï¼šç›®æ ‡1-5çš„é€‚é…æ€§
    ])

    # 3. åˆå§‹åŒ–åŠ¨æ€æ±‚è§£å™¨
    solver = DynamicTargetWeaponAssignment(
        initial_situation=initial_situation,
        adaptability_matrix=adaptability_matrix,
        damage_threshold=0.8,
        max_decision_time=5.0
    )

    # 4. å¯åŠ¨åœ¨çº¿å†³ç­–å¾ªç¯ï¼ˆå¦èµ·çº¿ç¨‹è¿è¡Œæ€åŠ¿å‘é€æ¨¡æ‹Ÿï¼‰
    from SituationReceiver import SituationSender
    sender = SituationSender()
    sender_thread = threading.Thread(target=sender.simulate_irregular_sending, args=(3, 30, 60), daemon=True)
    sender_thread.start()

    # 5. è¿è¡Œåœ¨çº¿å†³ç­–
    solver.run_online_loop(task_end_condition)


if __name__ == "__main__":
    main()